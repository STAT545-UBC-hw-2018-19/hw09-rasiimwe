cloud <- wordcloud(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=4)
saveWidget(cloud,"cloud.html",selfcontained = F)
webshot::webshot("cloud.html","cloud.png",vwidth = 1992, vheight = 1744, delay =10)
install.packages("webshot")
install.packages("webshot")
webshot::install_phantomjs()
library(wordcloud2)
library(wordcloud)
cloud <- wordcloud(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=4)
cloud <- wordcloud(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=6)
saveWidget(cloud,"cloud.html",selfcontained = F)
library(saveWidget)
Libary(wordcloud2)
libary(wordcloud2)
library(wordcloud2)
install.packages("wordcloud2")
saveWidget(cloud,"cloud.html",selfcontained = F)
webshot::webshot("cloud.html","cloud.png",vwidth = 1992, vheight = 1744, delay =10)
library("htmlwidgets")
saveWidget(cloud,"cloud.html",selfcontained = F)
library(webshot)
webshot::install_phantomjs()
cloud <- wordcloud2(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=6)
cloud <- wordcloud(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=6)
library("htmlwidgets")
saveWidget(cloud,"cloud.html",selfcontained = F)
wordcloud::saveWidget(cloud,"cloud.html",selfcontained = F)
wordcloud2::saveWidget(cloud,"cloud.html",selfcontained = F)
cloud <- wordcloud2(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=6)
png("cloud.png", width=1280,height=800)
cloud <- wordcloud2(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=6)
dev.off()
cloud <- wordcloud2(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=6)
dev.copy2png(file="cloud.png", width = 5, height = 5)
cloud <- wordcloud2(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=6)
dev.copy2pdf(file="cloud.pdf", width = 5, height = 5)
png("cloud.png", width=1280,height=800)
cloud <- wordcloud2(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=6)
dev.copy2pdf(file="cloud.pdf", width = 10, height = 10)
cloud <- wordcloud2(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=6)
dev.copy2pdf(file="cloud.pdf", width = 10, height = 10)
dev.off()
cloud <- wordcloud2(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=4)
dev.copy2pdf(file="cloud.pdf", width = 10, height = 10)
dev.off()
cloud <- wordcloud2(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=4)
png(file="cloud.pdf", width = 10, height = 10)
dev.off()
cloud <- wordcloud2(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=4)
png(file="cloud.png", width = 10, height = 10)
dev.off()
png("cloud.png", width=1280,height=800)
cloud <- wordcloud2(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=4)
dev.off()
cloud <- wordcloud2(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=4)
dev.copy2pdf(file="cloud.pdf", width = 10, height = 10)
dev.off()
cloud <- wordcloud2(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=4)
dev.copy2pdf(file="cloud.pdf", width = 10, height = 10)
common
set.seed(1234)
cloud <- wordcloud2(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=4)
dev.copy2pdf(file="cloud.pdf", width = 10, height = 10)
dev.off()
set.seed(1234)
cloud <- wordcloud2(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=4)
dev.copy2pdf(file="cloud.pdf", width = 10, height = 10)
dev.on()
dev()
cloud <- wordcloud2(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=4)
dev.copy2pdf(file="cloud.pdf", width = 10, height = 10)
cloud <- wordcloud2(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=4)
dev.copy2pdf(file="cloud.pdf", width = 10, height = 10)
dev.off()
cloud <- wordcloud2(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=4)
dev.copy2pdf(file="cloud.pdf", width = 10, height = 10)
suppressPackageStartupMessages(library(ggplot2)) #will be required to make some plots
suppressPackageStartupMessages(library(tidyverse)) #provides system of packages for data manipulation
suppressPackageStartupMessages(library(purrr))#to provide tools for working with functions and vectors like map()
suppressPackageStartupMessages(library(RColorBrewer))#provide color palette
suppressPackageStartupMessages(library(tibble))
suppressPackageStartupMessages(library(repurrrsive))
suppressPackageStartupMessages(library(tidytext))
suppressPackageStartupMessages(library(dplyr))# for required data manipulation
suppressPackageStartupMessages(library(stringr)) #avails string functions
suppressPackageStartupMessages(library(tm))
suppressPackageStartupMessages(library(SnowballC))
suppressPackageStartupMessages(library(wordcloud))
suppressPackageStartupMessages(library(RColorBrewer))
#loading merged dataset
trump_tweets_df<-read.csv("files/dataset_merge.txt", sep=",")
#creating neader dataset to work with- tweets2
regex_words <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"
tweets2 <- trump_tweets_df %>%
filter(!str_detect(Text, "^QRT")) %>%
mutate(Text = str_replace_all(Text, "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https", "")) %>%
unnest_tokens(word, Text, token = "regex", pattern = regex_words) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]"))
words <- tweets2$word
words <- Corpus(VectorSource(words))
#inspect(words)
#Build a term-document matrix
data_matrix <- TermDocumentMatrix(words)
mtx <- as.matrix(data_matrix)
sort_mtx <- sort(rowSums(mtx),decreasing=TRUE)
word_freq <- data.frame(word = names(sort_mtx),freq=sort_mtx)
#head(d, 10)
#write.table(word_freq, "files/word_freq.tsv",
#		sep = "\t", row.names = FALSE, quote = FALSE)
install.packages("wordcloud2")
set.seed(1234)
cloud <- wordcloud2(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=4)
dev.copy2pdf(file="cloud.pdf", width = 10, height = 10)
install.packages("wordcloud2")
cloud <- wordcloud2(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=4)
dev.copy2pdf(file="cloud.pdf", width = 10, height = 10)
cloud <- wordcloud2(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=4)
cloud <- wordcloud(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=4)
trump_tweets_df<-read.csv("files/dataset_merge.txt", sep=",")
#creating neader dataset to work with- tweets2
regex_words <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"
tweets2 <- trump_tweets_df %>%
filter(!str_detect(Text, "^QRT")) %>%
mutate(Text = str_replace_all(Text, "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https", "")) %>%
unnest_tokens(word, Text, token = "regex", pattern = regex_words) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]"))
words <- tweets2$word
words <- Corpus(VectorSource(words))
#inspect(words)
#Build a term-document matrix
data_matrix <- TermDocumentMatrix(words)
mtx <- as.matrix(data_matrix)
sort_mtx <- sort(rowSums(mtx),decreasing=TRUE)
word_freq <- data.frame(word = names(sort_mtx),freq=sort_mtx)
#head(d, 10)
#write.table(word_freq, "files/word_freq.tsv",
#		sep = "\t", row.names = FALSE, quote = FALSE)
trump_tweets_df<-read.csv("files/dataset_merge.txt", sep=",")
trump_tweets_df<-read.csv("files/dataset_merge.txt", sep=",")
regex_words <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"
tweets2 <- trump_tweets_df %>%
filter(!str_detect(Text, "^QRT")) %>%
mutate(Text = str_replace_all(Text, "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https", "")) %>%
unnest_tokens(word, Text, token = "regex", pattern = regex_words) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]"))
words <- tweets2$word
words <- Corpus(VectorSource(words))
data_matrix <- TermDocumentMatrix(words)
mtx <- as.matrix(data_matrix)
sort_mtx <- sort(rowSums(mtx),decreasing=TRUE)
word_freq <- data.frame(word = names(sort_mtx),freq=sort_mtx)
#head(d, 10)
set.seed(1234)
cloud <- wordcloud(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=4)
dev.copy2pdf(file="cloud.pdf", width = 10, height = 10)
cloud <- wordcloud(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=4)
dev.copy2pdf(file="cloud.pdf", width = 10, height = 10)
cloud <- wordcloud(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=4)
dev.copy2pdf(file="cloud.pdf", width = 10, height = 10)
cloud <- wordcloud(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=3)
dev.copy2pdf(file="cloud.pdf", width = 5, height = 5)
cloud <- wordcloud(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=3)
dev.copy2pdf(file="cloud.pdf", width = 3, height = 3)
bar_plot <- common_words %>%  ggplot(aes(word, n)) +
geom_bar(stat = 'identity', fill=c("gray50")) +
xlab(NULL) +
ylab(paste('Word count', sep = '')) +
ggtitle(paste('common words in Trumps tweets')) +
theme(legend.position="none") +
coord_flip() +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
ggsave("files/bar_plot.png", bar_plot)
trump_tweets_df<-read.csv("files/dataset_merge.txt", sep=",")
regex_words <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"
tweets2 <- trump_tweets_df %>%
filter(!str_detect(Text, "^QRT")) %>%
mutate(Text = str_replace_all(Text, "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https", "")) %>%
unnest_tokens(word, Text, token = "regex", pattern = regex_words) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]"))
words <- tweets2$word
words <- Corpus(VectorSource(words))
#inspect(words)
#Build a term-document matrix
data_matrix <- TermDocumentMatrix(words)
mtx <- as.matrix(data_matrix)
sort_mtx <- sort(rowSums(mtx),decreasing=TRUE)
word_freq <- data.frame(word = names(sort_mtx),freq=sort_mtx)
#head(d, 10)
#write.table(word_freq, "files/word_freq.tsv",
#		sep = "\t", row.names = FALSE, quote = FALSE)
set.seed(1234)
cloud <- wordcloud(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=3)
dev.copy2pdf(file="files/cloud.pdf", width = 3, height = 3)
common_words <- tweets2 %>%
count(word, sort=TRUE) %>%
filter(substr(word, 1, 1) != '#', # omiting hashtags
substr(word, 1, 1) != '@', # omiting Twitter handles
n > 80) %>% # only most common words
mutate(word = reorder(word, n))
write.table(common_words, "common_words.tsv",
sep = "\t", row.names = FALSE, quote = FALSE)
bar_plot <- common_words %>%  ggplot(aes(word, n)) +
geom_bar(stat = 'identity', fill=c("gray50")) +
xlab(NULL) +
ylab(paste('Word count', sep = '')) +
ggtitle(paste('common words in Trumps tweets')) +
theme(legend.position="none") +
coord_flip() +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
ggsave("files/bar_plot.png", bar_plot)
View(common_words)
names(common_words)[names(common_words)=='n'] <- 'word_frequency'
common_words <- tweets2 %>%
count(word, sort=TRUE) %>%
filter(substr(word, 1, 1) != '#', # omiting hashtags
substr(word, 1, 1) != '@', # omiting Twitter handles
n > 80) %>% # only most common words
mutate(word = reorder(word, n))
names(common_words)[names(common_words)=='n'] <- 'word_frequency'
write.table(common_words, "common_words.tsv",
sep = "\t", row.names = FALSE, quote = FALSE)
bar_plot <- common_words %>%  ggplot(aes(word, word_frequency)) +
geom_bar(stat = 'identity', fill=c("gray50")) +
xlab(NULL) +
ylab(paste('Word count', sep = '')) +
ggtitle(paste('common words in Trumps tweets')) +
theme(legend.position="none") +
coord_flip() +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
ggsave("files/bar_plot.png", bar_plot)
cloud <- wordcloud(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=3)
dev.copy2pdf(file="files/cloud.pdf", width = 10, height = 10) #used to render cloud
trump_tweets_df<-read.csv("files/dataset_merge.txt", sep=",")
regex_words <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"
tweets2 <- trump_tweets_df %>%
filter(!str_detect(Text, "^QRT")) %>%
mutate(Text = str_replace_all(Text, "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https", "")) %>%
unnest_tokens(word, Text, token = "regex", pattern = regex_words) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]"))
words <- tweets2$word
words <- Corpus(VectorSource(words))
#inspect(words)
#Build a term-document matrix
data_matrix <- TermDocumentMatrix(words)
mtx <- as.matrix(data_matrix)
sort_mtx <- sort(rowSums(mtx),decreasing=TRUE)
word_freq <- data.frame(word = names(sort_mtx),freq=sort_mtx)
#head(d, 10)
#write.table(word_freq, "files/word_freq.tsv",
#		sep = "\t", row.names = FALSE, quote = FALSE)
set.seed(1234)
cloud <- wordcloud(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=3)
dev.copy2pdf(file="files/cloud.pdf", width = 10, height = 10)
cloud <- wordcloud(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=3)
dev.copy2pdf(file="files/cloud.pdf", width = 7, height = 7) #used to render cloud
cloud <- wordcloud(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=3)
dev.copy2pdf(file="files/cloud.pdf", width = 5, height = 5) #used to render cloud
cloud <- wordcloud(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=3)
dev.copy2pdf(file="files/cloud.pdf", width = 6, height = 6) #used to render cloud
cloud <- wordcloud(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=3)
dev.copy2pdf(file="files/cloud.pdf", width = 7, height = 7) #used to render cloud
---
title: "trump_words.rmd"
author: "Rebecca Asiimwe"
date: '2018-11-27'
output: github_document
---
## Install required packages
```{r}
# Install following packages
#install.packages("tm")  # for text mining
#install.packages("SnowballC") # for text stemming
#install.packages("wordcloud") # word-cloud generator
#install.packages("RColorBrewer") # color palettes
#install.packages("webshot")
#webshot::install_phantomjs()
#load
suppressPackageStartupMessages(library(ggplot2)) #will be required to make some plots
suppressPackageStartupMessages(library(tidyverse)) #provides system of packages for data manipulation
suppressPackageStartupMessages(library(purrr))#to provide tools for working with functions and vectors like map()
suppressPackageStartupMessages(library(RColorBrewer))#provide color palette
suppressPackageStartupMessages(library(tibble))
suppressPackageStartupMessages(library(repurrrsive))
suppressPackageStartupMessages(library(tidytext))
suppressPackageStartupMessages(library(dplyr))# for required data manipulation
suppressPackageStartupMessages(library(stringr)) #avails string functions
suppressPackageStartupMessages(library(tm))
suppressPackageStartupMessages(library(SnowballC))
suppressPackageStartupMessages(library(wordcloud))
suppressPackageStartupMessages(library(RColorBrewer))
```
```{r}
#loading merged dataset
trump_tweets_df<-read.csv("files/dataset_merge.txt", sep=",")
#creating neader dataset to work with- tweets2
regex_words <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"
tweets2 <- trump_tweets_df %>%
filter(!str_detect(Text, "^QRT")) %>%
mutate(Text = str_replace_all(Text, "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https", "")) %>%
unnest_tokens(word, Text, token = "regex", pattern = regex_words) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]"))
words <- tweets2$word
words <- Corpus(VectorSource(words))
#inspect(words)
#Build a term-document matrix
data_matrix <- TermDocumentMatrix(words)
mtx <- as.matrix(data_matrix)
sort_mtx <- sort(rowSums(mtx),decreasing=TRUE)
word_freq <- data.frame(word = names(sort_mtx),freq=sort_mtx)
#head(d, 10)
#write.table(word_freq, "files/word_freq.tsv",
#		sep = "\t", row.names = FALSE, quote = FALSE)
set.seed(1234)
wordcloud(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=3)
#dev.copy2pdf(file="files/cloud.pdf", width = 7, height = 7) #used to render cloud
common_words <- tweets2 %>%
count(word, sort=TRUE) %>%
filter(substr(word, 1, 1) != '#', # omiting hashtags
substr(word, 1, 1) != '@', # omiting Twitter handles
n > 80) %>% # only most common words
mutate(word = reorder(word, n))
names(common_words)[names(common_words)=='n'] <- 'word_frequency'
write.table(common_words, "common_words.tsv",
sep = "\t", row.names = FALSE, quote = FALSE)
common_words %>%  ggplot(aes(word, word_frequency)) +
geom_bar(stat = 'identity', fill=c("gray50")) +
xlab(NULL) +
ylab(paste('Word count', sep = '')) +
ggtitle(paste('common words in Trumps tweets')) +
theme(legend.position="none") +
coord_flip() +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
#ggsave("files/bar_plot.png", bar_plot)
```
#loading merged dataset
trump_tweets_df<-read.csv("files/dataset_merge.txt", sep=",")
#creating neader dataset to work with- tweets2
regex_words <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"
tweets2 <- trump_tweets_df %>%
filter(!str_detect(Text, "^QRT")) %>%
mutate(Text = str_replace_all(Text, "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https", "")) %>%
unnest_tokens(word, Text, token = "regex", pattern = regex_words) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]"))
words <- tweets2$word
words <- Corpus(VectorSource(words))
#inspect(words)
#Build a term-document matrix
data_matrix <- TermDocumentMatrix(words)
mtx <- as.matrix(data_matrix)
sort_mtx <- sort(rowSums(mtx),decreasing=TRUE)
word_freq <- data.frame(word = names(sort_mtx),freq=sort_mtx)
#head(d, 10)
#write.table(word_freq, "files/word_freq.tsv",
#		sep = "\t", row.names = FALSE, quote = FALSE)
set.seed(1234)
wordcloud(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=3)
#dev.copy2pdf(file="files/cloud.pdf", width = 7, height = 7) #used to render cloud
common_words <- tweets2 %>%
count(word, sort=TRUE) %>%
filter(substr(word, 1, 1) != '#', # omiting hashtags
substr(word, 1, 1) != '@', # omiting Twitter handles
n > 80) %>% # only most common words
mutate(word = reorder(word, n))
names(common_words)[names(common_words)=='n'] <- 'word_frequency'
write.table(common_words, "common_words.tsv",
sep = "\t", row.names = FALSE, quote = FALSE)
common_words %>%  ggplot(aes(word, word_frequency)) +
geom_bar(stat = 'identity', fill=c("gray50")) +
xlab(NULL) +
ylab(paste('Word count', sep = '')) +
ggtitle(paste('common words in Trumps tweets')) +
theme(legend.position="none") +
coord_flip() +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
#ggsave("files/bar_plot.png", bar_plot)
#loading merged dataset
trump_tweets_df<-read.csv("files/dataset_merge.txt", sep=",")
#creating neader dataset to work with- tweets2
regex_words <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"
tweets2 <- trump_tweets_df %>%
filter(!str_detect(Text, "^QRT")) %>%
mutate(Text = str_replace_all(Text, "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https", "")) %>%
unnest_tokens(word, Text, token = "regex", pattern = regex_words) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]"))
words <- tweets2$word
words <- Corpus(VectorSource(words))
#inspect(words)
#Build a term-document matrix
data_matrix <- TermDocumentMatrix(words)
mtx <- as.matrix(data_matrix)
sort_mtx <- sort(rowSums(mtx),decreasing=TRUE)
word_freq <- data.frame(word = names(sort_mtx),freq=sort_mtx)
#head(d, 10)
#write.table(word_freq, "files/word_freq.tsv",
#		sep = "\t", row.names = FALSE, quote = FALSE)
set.seed(1234)
wordcloud(words = word_freq$word, freq = word_freq$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"), size=6)
#dev.copy2pdf(file="files/cloud.pdf", width = 7, height = 7) #used to render cloud
common_words <- tweets2 %>%
count(word, sort=TRUE) %>%
filter(substr(word, 1, 1) != '#', # omiting hashtags
substr(word, 1, 1) != '@', # omiting Twitter handles
n > 80) %>% # only most common words
mutate(word = reorder(word, n))
names(common_words)[names(common_words)=='n'] <- 'word_frequency'
write.table(common_words, "common_words.tsv",
sep = "\t", row.names = FALSE, quote = FALSE)
common_words %>%  ggplot(aes(word, word_frequency)) +
geom_bar(stat = 'identity', fill=c("gray50")) +
xlab(NULL) +
ylab(paste('Word count', sep = '')) +
ggtitle(paste('common words in Trumps tweets')) +
theme(legend.position="none") +
coord_flip() +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
#ggsave("files/bar_plot.png", bar_plot)
