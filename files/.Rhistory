trump_tweets_df<-read.csv("data.csv.txt", sep=",")
tweets <- trump_tweets_df$Text #subseting the data to work with a small piece of it
words <- regex <- "badly|crazy|weak|spent|strong|dumb|joke|guns|funny|dead" #common words associated with Trump tweets
tweets <- tweets[c(2, 4, 6, 8)]
str(tweets) #character of 4 elements
tweets
regex_words <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"
tweets2 <- trump_tweets_df %>%
filter(!str_detect(Text, "^QRT")) %>%
mutate(Text = str_replace_all(Text, "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https", "")) %>%
unnest_tokens(word, Text, token = "regex", pattern = regex_words) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]"))
words <- tweets2$word
words <- Corpus(VectorSource(words))
inspect(words)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
words <- tm_map(words, toSpace, "/")
words <- tm_map(words, toSpace, "@")
words <- tm_map(words, toSpace, "\\|")
##some cleaning
#Convert the text to lower case
words <- tm_map(words, content_transformer(tolower))
# Remove numbers
words <- tm_map(words, removeNumbers)
# Remove punctuations
words <- tm_map(words, removePunctuation)
# Eliminate extra white spaces
words <- tm_map(words, stripWhitespace)
# Text stemming
# docs <- tm_map(docs, stemDocument)
#Build a term-document matrix
dtm <- TermDocumentMatrix(words)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
trump_tweets_df<-read.csv("data.csv.txt", sep=",")
trump_tweets_df<-read.csv("file_1.txt", sep=",")
trump_tweets_df<-read.csv("file_1.txt", sep=",")
tweets <- trump_tweets_df$Text #subseting the data to work with a small piece of it
words <- regex <- "badly|crazy|weak|spent|strong|dumb|joke|guns|funny|dead" #common words associated with Trump tweets
tweets <- tweets[c(2, 4, 6, 8)]
str(tweets) #character of 4 elements
tweets
regex_words <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"
tweets2 <- trump_tweets_df %>%
filter(!str_detect(Text, "^QRT")) %>%
mutate(Text = str_replace_all(Text, "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https", "")) %>%
unnest_tokens(word, Text, token = "regex", pattern = regex_words) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]"))
suppressPackageStartupMessages(library(dplyr))# for required data manipulation
regex_words <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"
tweets2 <- trump_tweets_df %>%
filter(!str_detect(Text, "^QRT")) %>%
mutate(Text = str_replace_all(Text, "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https", "")) %>%
unnest_tokens(word, Text, token = "regex", pattern = regex_words) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]"))
suppressPackageStartupMessages(library(dplyr))# for required data manipulation
suppressPackageStartupMessages(library(stringr)) #avails string functions
regex_words <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"
tweets2 <- trump_tweets_df %>%
filter(!str_detect(Text, "^QRT")) %>%
mutate(Text = str_replace_all(Text, "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https", "")) %>%
unnest_tokens(word, Text, token = "regex", pattern = regex_words) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]"))
suppressPackageStartupMessages(library(ggplot2)) #will be required to make some plots
suppressPackageStartupMessages(library(tidyverse)) #provides system of packages for data manipulation
suppressPackageStartupMessages(library(purrr))#to provide tools for working with functions and vectors like map()
suppressPackageStartupMessages(library(RColorBrewer))#provide color palette
suppressPackageStartupMessages(library(tibble))
suppressPackageStartupMessages(library(repurrrsive))
suppressPackageStartupMessages(library(tidytext))
suppressPackageStartupMessages(library(dplyr))# for required data manipulation
suppressPackageStartupMessages(library(stringr)) #avails string functions
regex_words <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"
tweets2 <- trump_tweets_df %>%
filter(!str_detect(Text, "^QRT")) %>%
mutate(Text = str_replace_all(Text, "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https", "")) %>%
unnest_tokens(word, Text, token = "regex", pattern = regex_words) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]"))
simple_page <- read_html("cm111-simple_script.htm")
library(tidyverse)
library(rvest)
simple_page <- read_html("cm111-simple_script.htm")
simple_page %>% html_structure()
simple_page %>% html_text()
simple_page %>% html_text() %>% cat()
simple_page %>% html_text() #%>%# cat()
